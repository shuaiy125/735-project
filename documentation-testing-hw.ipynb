{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19c41f88",
      "metadata": {
        "id": "19c41f88"
      },
      "source": [
        "# Homework: Documenting Your Code + Testing Your Code\n",
        "\n",
        "## Problem 1 - Write docstrings\n",
        "\n",
        "The following functions are missing docstrings. Write Google-style docstrings for each function, including `Args`, `Returns`, and `Raises` sections where appropriate. Make sure to document default values and explain what each parameter means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cacdf2c",
      "metadata": {
        "id": "2cacdf2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(data, method=\"zscore\"):\n",
        "    if method == \"zscore\":\n",
        "        return (data - np.mean(data)) / np.std(data)\n",
        "    elif method == \"minmax\":\n",
        "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "\n",
        "def weighted_mean(values, weights=None):\n",
        "    if weights is None:\n",
        "        return np.mean(values)\n",
        "    if len(values) != len(weights):\n",
        "        raise ValueError(\"values and weights must have the same length\")\n",
        "    return np.sum(values * weights) / np.sum(weights)\n",
        "\n",
        "\n",
        "def remove_outliers(data, threshold=3.0):\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    mask = np.abs(data - mean) <= threshold * std\n",
        "    return data[mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16fb210",
      "metadata": {
        "id": "f16fb210"
      },
      "source": [
        "## Problem 2 - Add type hints\n",
        "\n",
        "The following functions have incomplete or missing type hints. Add appropriate type hints for all parameters and return values. Use `|` syntax for union types where a parameter can accept multiple types or return `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e458a748",
      "metadata": {
        "id": "e458a748"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def clip_values(arr, lower, upper):\n",
        "    \"\"\"Clip array values to be within [lower, upper] range.\"\"\"\n",
        "    return np.clip(arr, lower, upper)\n",
        "\n",
        "\n",
        "def find_peaks(data, min_height=None):\n",
        "    \"\"\"Find indices where values are local maxima above min_height.\n",
        "\n",
        "    Returns None if no peaks are found.\n",
        "    \"\"\"\n",
        "    peaks = []\n",
        "    for i in range(1, len(data) - 1):\n",
        "        if data[i] > data[i - 1] and data[i] > data[i + 1]:\n",
        "            if min_height is None or data[i] >= min_height:\n",
        "                peaks.append(i)\n",
        "    if len(peaks) == 0:\n",
        "        return None\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def summarize(data, stats):\n",
        "    \"\"\"Calculate summary statistics for data.\n",
        "\n",
        "    Args:\n",
        "        data: Input array of numeric values.\n",
        "        stats: List of statistic names to compute.\n",
        "            Valid options: \"mean\", \"median\", \"std\", \"min\", \"max\"\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping statistic names to computed values.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for stat in stats:\n",
        "        if stat == \"mean\": result[stat] = np.mean(data)\n",
        "        elif stat == \"median\":\n",
        "            result[stat] = np.median(data)\n",
        "        elif stat == \"std\":\n",
        "            result[stat] = np.std(data)\n",
        "        elif stat == \"min\":\n",
        "            result[stat] = np.min(data)\n",
        "        elif stat == \"max\":\n",
        "            result[stat] = np.max(data)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66a6400",
      "metadata": {
        "id": "b66a6400"
      },
      "source": [
        "## Problem 3: Identifying Test Types\n",
        "\n",
        "For each scenario below, identify whether the test being described is a **unit test**, **integration test**, or **regression test**. Briefly explain your reasoning.\n",
        "\n",
        "**(a)** You write a test that verifies `calculate_variance()` returns 0 for the input `[3.0, 3.0, 3.0]`.\n",
        "\n",
        "**(b)** After discovering that `fit_model()` crashes when given a dataset with a single row, you fix the bug and add a test with a one-row input.\n",
        "\n",
        "**(c)** You write a test that loads data from a CSV file, passes it through `clean_data()`, fits a model with `fit_linear_regression()`, and verifies the model's R-squared value is within an expected range.\n",
        "\n",
        "**(d)** A user reports that `normalize()` returns incorrect values when all input values are negative. After fixing the issue, you add a test with input `[-5.0, -3.0, -1.0]`.\n",
        "\n",
        "## Problem 4: Code Review - What's Wrong with These Tests?\n",
        "\n",
        "Review the following test code and identify at least **four** problems with the test design or implementation. Explain why each is problematic and suggest how to fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0f31e7",
      "metadata": {
        "id": "bb0f31e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_all_statistics():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "\n",
        "    # Test mean\n",
        "    assert np.mean(data) == 30\n",
        "\n",
        "    # Test median\n",
        "    assert np.median(data) == 30\n",
        "\n",
        "    # Test standard deviation\n",
        "    assert np.std(data) > 0\n",
        "\n",
        "    # Test min and max\n",
        "    assert np.min(data) == 10\n",
        "    assert np.max(data) == 50\n",
        "\n",
        "    # Test sum\n",
        "    assert np.sum(data) == 150\n",
        "\n",
        "def verify_variance_positive(arr):\n",
        "    var = np.var(arr)\n",
        "    assert var >= 0\n",
        "\n",
        "def test_correlation():\n",
        "    x = np.array([1.0, 2.0, 3.0])\n",
        "    y = np.array([2.0, 4.0, 6.0])\n",
        "    corr = np.corrcoef(x, y)[0, 1]\n",
        "    assert corr == 1.0\n",
        "\n",
        "results = []\n",
        "\n",
        "def test_append_result():\n",
        "    global results\n",
        "    results.append(42)\n",
        "    assert 42 in results\n",
        "\n",
        "def test_check_results():\n",
        "    assert len(results) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3030fab2",
      "metadata": {
        "id": "3030fab2"
      },
      "source": [
        "## Problem 5: The Flaky Test\n",
        "\n",
        "Your colleague wrote the following test for a bootstrap confidence interval function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235ca02a",
      "metadata": {
        "id": "235ca02a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def bootstrap_ci(data, confidence=0.95, n_bootstrap=1000):\n",
        "    \"\"\"Compute bootstrap confidence interval for the mean.\"\"\"\n",
        "    means = []\n",
        "    n = len(data)\n",
        "    for _ in range(n_bootstrap):\n",
        "        sample = np.random.choice(data, size=n, replace=True)\n",
        "        means.append(np.mean(sample))\n",
        "\n",
        "    alpha = 1 - confidence\n",
        "    lower = np.percentile(means, 100 * alpha / 2)\n",
        "    upper = np.percentile(means, 100 * (1 - alpha / 2))\n",
        "    return lower, upper\n",
        "\n",
        "def test_bootstrap_ci_contains_true_mean():\n",
        "    data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "    true_mean = 5.5\n",
        "    lower, upper = bootstrap_ci(data)\n",
        "    assert lower < true_mean < upper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860f28d3",
      "metadata": {
        "id": "860f28d3"
      },
      "source": [
        "**(a)** The test passes most of the time but occasionally fails. Explain why this test is \"flaky\" (non-deterministic).\n",
        "\n",
        "**(b)** Your colleague argues: \"The test is correct because a 95% confidence interval should contain the true mean 95% of the time, so occasional failures are expected.\" Is this a good argument for keeping the test as-is? Why or why not?\n",
        "\n",
        "**(c)** Rewrite the test to be deterministic and reliable while still meaningfully testing the `bootstrap_ci` function. Your solution should: ensure reproducible results and verify that the confidence interval has reasonable properties.\n",
        "\n",
        "**(d)** Propose an alternative testing strategy that could verify the 95% coverage property without making the test flaky. You don't need to implement it, but describe the approach."
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}