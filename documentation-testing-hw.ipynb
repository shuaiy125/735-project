{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19c41f88",
      "metadata": {
        "id": "19c41f88"
      },
      "source": [
        "# Homework: Documenting Your Code + Testing Your Code\n",
        "\n",
        "## Problem 1 - Write docstrings\n",
        "\n",
        "The following functions are missing docstrings. Write Google-style docstrings for each function, including `Args`, `Returns`, and `Raises` sections where appropriate. Make sure to document default values and explain what each parameter means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cacdf2c",
      "metadata": {
        "id": "2cacdf2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(data, method=\"zscore\"):\n",
        "    \"\"\"Normalizes a dataset using the specified method.\n",
        "\n",
        "    Standardizes or scales input data to a common range or distribution.\n",
        "    Supports Z-score standardization (default) and Min-Max scaling.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): The input data to be normalized. Can be a list,\n",
        "            tuple, or NumPy array.\n",
        "        method (str, optional): The normalization technique to use.\n",
        "            Options are:\n",
        "            * 'zscore': Standardizes data to have a mean of 0 and a\n",
        "                standard deviation of 1.\n",
        "            * 'minmax': Scales data to the range [0, 1].\n",
        "            Defaults to \"zscore\".\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: An array containing the normalized data.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If `method` is not \"zscore\" or \"minmax\".\n",
        "    \"\"\"\n",
        "    if method == \"zscore\":\n",
        "        return (data - np.mean(data)) / np.std(data)\n",
        "    elif method == \"minmax\":\n",
        "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "\n",
        "def weighted_mean(values, weights=None):\n",
        "    \"\"\"Calculates the arithmetic or weighted mean of a set of values.\n",
        "\n",
        "    If weights are provided, computes the weighted average where each value\n",
        "    contributes according to its corresponding weight. If no weights are\n",
        "    provided, computes the standard arithmetic mean.\n",
        "\n",
        "    Args:\n",
        "        values (array-like): The input values to average. Can be a list,\n",
        "            tuple, or NumPy array.\n",
        "        weights (array-like, optional): An array of weights corresponding to\n",
        "            `values`. If provided, must have the same length as `values`.\n",
        "            Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated mean (weighted or arithmetic).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If `weights` is provided but does not have the same\n",
        "            length as `values`.\n",
        "    \"\"\"\n",
        "    if weights is None:\n",
        "        return np.mean(values)\n",
        "    if len(values) != len(weights):\n",
        "        raise ValueError(\"values and weights must have the same length\")\n",
        "    return np.sum(values * weights) / np.sum(weights)\n",
        "\n",
        "def remove_outliers(data, threshold=3.0):\n",
        "    \"\"\"Removes outliers from a dataset based on Z-score thresholding.\n",
        "\n",
        "    Filters out data points that lie more than a specified number of standard\n",
        "    deviations away from the mean. This assumes the data follows a roughly\n",
        "    normal distribution.\n",
        "\n",
        "    Args:\n",
        "        data (numpy.ndarray): The input data array containing numerical values.\n",
        "        threshold (float, optional): The Z-score threshold. Data points with a\n",
        "            Z-score absolute value greater than this will be removed.\n",
        "            Defaults to 3.0.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A filtered array with outliers removed.\n",
        "    \"\"\"\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    mask = np.abs(data - mean) <= threshold * std\n",
        "    return data[mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16fb210",
      "metadata": {
        "id": "f16fb210"
      },
      "source": [
        "## Problem 2 - Add type hints\n",
        "\n",
        "The following functions have incomplete or missing type hints. Add appropriate type hints for all parameters and return values. Use `|` syntax for union types where a parameter can accept multiple types or return `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e458a748",
      "metadata": {
        "id": "e458a748"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def clip_values(arr: np.ndarray, lower: float | int, upper: float | int) -> np.ndarray:\n",
        "    \"\"\"Clip array values to be within [lower, upper] range.\"\"\"\n",
        "    return np.clip(arr, lower, upper)\n",
        "\n",
        "\n",
        "def find_peaks(data: list[float] | np.ndarray, min_height: float | int | None = None) -> list[int] | None:\n",
        "    \"\"\"Find indices where values are local maxima above min_height.\n",
        "\n",
        "    Returns None if no peaks are found.\n",
        "    \"\"\"\n",
        "    peaks = []\n",
        "    for i in range(1, len(data) - 1):\n",
        "        if data[i] > data[i - 1] and data[i] > data[i + 1]:\n",
        "            if min_height is None or data[i] >= min_height:\n",
        "                peaks.append(i)\n",
        "    if len(peaks) == 0:\n",
        "        return None\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def summarize(data: list[float] | np.ndarray, stats: list[str]) -> dict[str, float]:\n",
        "    \"\"\"Calculate summary statistics for data.\n",
        "\n",
        "    Args:\n",
        "        data: Input array of numeric values.\n",
        "        stats: List of statistic names to compute.\n",
        "            Valid options: \"mean\", \"median\", \"std\", \"min\", \"max\"\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping statistic names to computed values.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for stat in stats:\n",
        "        if stat == \"mean\":\n",
        "            result[stat] = float(np.mean(data))\n",
        "        elif stat == \"median\":\n",
        "            result[stat] = float(np.median(data))\n",
        "        elif stat == \"std\":\n",
        "            result[stat] = float(np.std(data))\n",
        "        elif stat == \"min\":\n",
        "            result[stat] = float(np.min(data))\n",
        "        elif stat == \"max\":\n",
        "            result[stat] = float(np.max(data))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66a6400",
      "metadata": {
        "id": "b66a6400"
      },
      "source": [
        "## Problem 3: Identifying Test Types\n",
        "\n",
        "For each scenario below, identify whether the test being described is a **unit test**, **integration test**, or **regression test**. Briefly explain your reasoning.\n",
        "\n",
        "**(a)** You write a test that verifies `calculate_variance()` returns 0 for the input `[3.0, 3.0, 3.0]`.\n",
        "\n",
        "This is a **unit test** because it tests a single function in isolation with a specific input to verify its correctness.\n",
        "\n",
        "**(b)** After discovering that `fit_model()` crashes when given a dataset with a single row, you fix the bug and add a test with a one-row input.\n",
        "\n",
        "This is a **regression test** because it ensures that a previously identified bug (crashing with a single-row dataset) does not reoccur in future versions of the code.\n",
        "\n",
        "**(c)** You write a test that loads data from a CSV file, passes it through `clean_data()`, fits a model with `fit_linear_regression()`, and verifies the model's R-squared value is within an expected range.\n",
        "\n",
        "This is an **integration test** because it tests multiple components (data loading, cleaning, and model fitting) working together to ensure they function correctly as a whole.\n",
        "\n",
        "**(d)** A user reports that `normalize()` returns incorrect values when all input values are negative. After fixing the issue, you add a test with input `[-5.0, -3.0, -1.0]`.\n",
        "\n",
        "This is a **regression test** because it verifies that a previously reported issue (incorrect normalization of negative values) has been resolved and does not reoccur in future versions.\n",
        "\n",
        "## Problem 4: Code Review - What's Wrong with These Tests?\n",
        "\n",
        "Review the following test code and identify at least **four** problems with the test design or implementation. Explain why each is problematic and suggest how to fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0f31e7",
      "metadata": {
        "id": "bb0f31e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pytest\n",
        "\n",
        "def test_calculate_mean():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.mean(data) == 30\n",
        "\n",
        "def test_calculate_median():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.median(data) == 30\n",
        "\n",
        "def test_standard_deviation():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.std(data) > 0\n",
        "\n",
        "def test_min():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.min(data) == 10\n",
        "\n",
        "def test_max():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.max(data) == 50\n",
        "\n",
        "def test_sum():   \n",
        "    data = [10, 20, 30, 40, 50]\n",
        "    assert np.sum(data) == 150\n",
        "\n",
        "def test_variance_positive(arr):\n",
        "    var = np.var(arr)\n",
        "    assert var >= 0\n",
        "\n",
        "def test_correlation():\n",
        "    x = np.array([1.0, 2.0, 3.0])\n",
        "    y = np.array([2.0, 4.0, 6.0])\n",
        "    corr = np.corrcoef(x, y)[0, 1]\n",
        "    assert corr == pytest.approx(1.0)\n",
        "\n",
        "\n",
        "def test_append_result():\n",
        "    results = []\n",
        "    results.append(42)\n",
        "    assert 42 in results\n",
        "    assert len(results) == 1\n",
        "\n",
        "def test_check_results():\n",
        "    results = []\n",
        "    assert len(results) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9596a3",
      "metadata": {},
      "source": [
        "The function test_all_statistics tests the mean, median, std, min, max, and sum all in a single block. If the assertion for mean fails, the test crashes immediately. This makes it hard to identify which specific statistic calculation is failing. The Fix: Break them into separate \"Unit\" tests. Each test should verify one specific behavior.\n",
        "\n",
        "Pytest will not run verify_variance_positiv since its name does not start with test_. The Fix: Rename the function to test_variance_positive.\n",
        "\n",
        "In test_correlation, the code uses assert corr == 1.0 to check for perfect correlation. However, floating-point arithmetic can introduce small precision errors, making direct equality checks unreliable. The Fix: Use a tolerance-based comparison, such as abs(corr - 1.0) < 1e-6.\n",
        "\n",
        "test_append_result and test_check_results rely on a global list named results to store intermediate results. This creates hidden dependencies between tests, making them order-dependent and harder to maintain. The Fix: Each test should manage its own state and not rely on shared global variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3030fab2",
      "metadata": {
        "id": "3030fab2"
      },
      "source": [
        "## Problem 5: The Flaky Test\n",
        "\n",
        "Your colleague wrote the following test for a bootstrap confidence interval function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235ca02a",
      "metadata": {
        "id": "235ca02a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def bootstrap_ci(data, confidence=0.95, n_bootstrap=1000):\n",
        "    \"\"\"Compute bootstrap confidence interval for the mean.\"\"\"\n",
        "    means = []\n",
        "    n = len(data)\n",
        "    for _ in range(n_bootstrap):\n",
        "        sample = np.random.choice(data, size=n, replace=True)\n",
        "        means.append(np.mean(sample))\n",
        "\n",
        "    alpha = 1 - confidence\n",
        "    lower = np.percentile(means, 100 * alpha / 2)\n",
        "    upper = np.percentile(means, 100 * (1 - alpha / 2))\n",
        "    return lower, upper\n",
        "\n",
        "def test_bootstrap_ci_contains_true_mean():\n",
        "    data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "    true_mean = 5.5\n",
        "    np.random.seed(42)\n",
        "    lower, upper = bootstrap_ci(data, confidence=0.95, n_bootstrap=1000)\n",
        "    assert lower <= upper\n",
        "    assert lower >= np.min(data)\n",
        "    assert upper <= np.max(data)\n",
        "    assert lower < sample_mean < upper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860f28d3",
      "metadata": {
        "id": "860f28d3"
      },
      "source": [
        "**(a)** The test passes most of the time but occasionally fails. Explain why this test is \"flaky\" (non-deterministic).\n",
        "\n",
        "The line assert lower < true_mean < upper demands that the interval capture the mean 100% of the time. Since the method relies on randomness, occasionally the random sampler will pick a skewed set of numbers (e.g., mostly 9s and 10s), shifting the interval enough that it no longer covers 5.5, causing the test to fail.\n",
        "\n",
        "**(b)** Your colleague argues: \"The test is correct because a 95% confidence interval should contain the true mean 95% of the time, so occasional failures are expected.\" Is this a good argument for keeping the test as-is? Why or why not?\n",
        "\n",
        "This is a bad argument because he/she is confusing statistical validity with test reliability. If the test fails, we don't know the answer. It could be broken code, or it could be \"bad luck\" (statistical noise). We need to verify that the Python implementation (the loop, the random choice, the percentile calculation) is correct. We can do this without actual randomness.\n",
        "\n",
        "**(c)** Rewrite the test to be deterministic and reliable while still meaningfully testing the `bootstrap_ci` function. Your solution should: ensure reproducible results and verify that the confidence interval has reasonable properties.\n",
        "\n",
        "Add a random seed in test_bootstrap_ci_contains_true_mean(). \n",
        "\n",
        "**(d)** Propose an alternative testing strategy that could verify the 95% coverage property without making the test flaky. You don't need to implement it, but describe the approach.\n",
        "\n",
        "Instead of checking if one interval captures the mean (which fails 5% of the time), check if the algorithm captures the mean roughly 95% of the time over many trials, and make that simulation reproducible."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "language_info": {
      "name": "plaintext"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
