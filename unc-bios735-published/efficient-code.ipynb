{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8792dfc",
   "metadata": {},
   "source": [
    "# Writing Efficient Code\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Python is widely used in scientific computing for its readability and extensive ecosystem. However, pure Python can be slow for computationally intensive tasks. A simple loop that runs millions of times can take seconds in Python but milliseconds in C or Fortran.\n",
    "\n",
    "For statistical computing, this matters. Monte Carlo simulations, bootstrap resampling, optimization algorithms, and large-scale data analysis often require executing the same operations millions of times. The difference between code that takes 10 seconds and code that takes 10 minutes can determine whether an analysis is practical.\n",
    "\n",
    "This lecture covers techniques to make Python code faster:\n",
    "\n",
    "* Profiling to identify bottlenecks before optimizing\n",
    "* Vectorization using NumPy\n",
    "* Parallelization using multiprocessing\n",
    "* Just-in-time (JIT) compilation with Numba\n",
    "* Interfacing with C/C++ using Cython\n",
    "\n",
    "The key principle is: **profile first, optimize second**. Most code spends the vast majority of its time in a small fraction of the codebase. Optimizing the wrong parts wastes effort and often makes code harder to read.\n",
    "\n",
    "## Profiling Your Code\n",
    "\n",
    "Before optimizing, you need to know where your code spends its time. Python provides built-in tools for this: `timeit` for quick benchmarks and `cProfile` for detailed analysis.\n",
    "\n",
    "### Using timeit\n",
    "\n",
    "The `timeit` module measures how long a small code snippet takes to execute. It runs the code multiple times and reports the average time, which gives more reliable measurements than a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f094508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 10000 runs: 0.1069 seconds\n",
      "Average time per run: 0.0107 ms\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# Time a simple expression\n",
    "time = timeit.timeit('sum(range(1000))', number=10000)\n",
    "print(f\"Total time for 10000 runs: {time:.4f} seconds\")\n",
    "print(f\"Average time per run: {time/10000*1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8b3b0",
   "metadata": {},
   "source": [
    "For timing functions, you can pass a setup string that runs once before the timing begins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a52acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy mean: 0.0149 seconds for 1000 runs\n",
      "Python mean: 0.2094 seconds for 1000 runs\n",
      "NumPy is 14.0x faster\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "setup = '''\n",
    "import numpy as np\n",
    "data = np.random.randn(10000)\n",
    "'''\n",
    "\n",
    "# Time NumPy operations\n",
    "numpy_time = timeit.timeit('np.mean(data)', setup=setup, number=1000)\n",
    "print(f\"NumPy mean: {numpy_time:.4f} seconds for 1000 runs\")\n",
    "\n",
    "# Compare with pure Python\n",
    "setup_python = '''\n",
    "import numpy as np\n",
    "data = list(np.random.randn(10000))\n",
    "'''\n",
    "python_time = timeit.timeit('sum(data)/len(data)', setup=setup_python, number=1000)\n",
    "print(f\"Python mean: {python_time:.4f} seconds for 1000 runs\")\n",
    "print(f\"NumPy is {python_time/numpy_time:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be55ce",
   "metadata": {},
   "source": [
    "In Jupyter notebooks or IPython, you can use the `%timeit` magic command for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2af15a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.83 µs ± 24.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b6a4d",
   "metadata": {},
   "source": [
    "This automatically determines how many iterations to run and reports statistics.\n",
    "\n",
    "### Using cProfile\n",
    "\n",
    "While `timeit` is useful for comparing specific snippets, `cProfile` analyzes an entire program and shows where time is spent across all function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "885126c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 28 06:56:46 2026    profile_stats\n",
      "\n",
      "         961 function calls (951 primitive calls) in 0.135 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 169 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.133    0.133 <string>:1(<module>)\n",
      "        1    0.004    0.004    0.132    0.132 1590960761.py:21(main)\n",
      "       10    0.097    0.010    0.121    0.012 1590960761.py:6(slow_variance)\n",
      "       10    0.024    0.002    0.024    0.002 {built-in method builtins.sum}\n",
      "        1    0.005    0.005    0.005    0.005 {built-in method numpy.array}\n",
      "        1    0.000    0.000    0.002    0.002 decorator.py:229(fun)\n",
      "        1    0.000    0.000    0.002    0.002 history.py:54(only_when_enabled)\n",
      "        1    0.000    0.000    0.001    0.001 history.py:826(writeout_cache)\n",
      "        1    0.001    0.001    0.001    0.001 {method 'randn' of 'numpy.random.mtrand.RandomState' objects}\n",
      "        1    0.000    0.000    0.001    0.001 history.py:814(_writeout_input_cache)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x110fdd550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def slow_variance(data):\n",
    "    \"\"\"Calculate variance using a slow approach.\"\"\"\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    total = 0\n",
    "    for x in data:\n",
    "        total += (x - mean) ** 2\n",
    "    return total / n\n",
    "\n",
    "\n",
    "def fast_variance(data):\n",
    "    \"\"\"Calculate variance using NumPy.\"\"\"\n",
    "    return np.var(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = list(np.random.randn(100000))\n",
    "    data_np = np.array(data)\n",
    "\n",
    "    for _ in range(10):\n",
    "        slow_variance(data)\n",
    "        fast_variance(data_np)\n",
    "\n",
    "\n",
    "# Profile the main function\n",
    "cProfile.run('main()', 'profile_stats')\n",
    "\n",
    "# Print sorted results\n",
    "stats = pstats.Stats('profile_stats')\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb0d39",
   "metadata": {},
   "source": [
    "The output shows:\n",
    "- `ncalls`: number of times the function was called\n",
    "- `tottime`: total time spent in the function (excluding subfunctions)\n",
    "- `cumtime`: cumulative time including subfunctions\n",
    "- `percall`: time per call\n",
    "\n",
    "Look for functions with high `tottime` or `cumtime` values. These are your optimization targets.\n",
    "\n",
    "### Question\n",
    "\n",
    "Consider the following profiling output:\n",
    "\n",
    "```\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "     1000    5.234    0.005    5.234    0.005 stats.py:15(compute_distances)\n",
    "     1000    0.012    0.000    0.012    0.000 stats.py:25(normalize)\n",
    "   100000    0.892    0.000    0.892    0.000 stats.py:30(update_centroid)\n",
    "        1    0.001    0.001    6.139    6.139 stats.py:40(kmeans)\n",
    "```\n",
    "\n",
    "Which function should you optimize first, and why?\n",
    "\n",
    "### Answer\n",
    "\n",
    "`compute_distances` should be optimized first. It has the highest `tottime` (5.234 seconds), meaning the program spends 85% of its total time (5.234 out of 6.139 seconds) inside this function. Although `update_centroid` is called 100 times more often, its total time is only 0.892 seconds. Optimizing `compute_distances` will have the largest impact on overall performance.\n",
    "\n",
    "### Line Profiler\n",
    "\n",
    "For more detailed analysis, the `line_profiler` package shows time spent on each line within a function. Install it with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc7d26e-fa0f-40ad-9768-975d8c899e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: line_profiler in /Users/daiwei/.pyenv/versions/experiment/lib/python3.12/site-packages (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af876c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a file: example.py\n",
    "from line_profiler import profile\n",
    "\n",
    "\n",
    "@profile\n",
    "def compute_pairwise_distances(X):\n",
    "    n = X.shape[0]\n",
    "    distances = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            diff = X[i] - X[j]\n",
    "            distances[i, j] = np.sqrt(np.sum(diff**2))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea89c7",
   "metadata": {},
   "source": [
    "Run with: `kernprof -l -v example.py`\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 2.45632 s\n",
    "File: example.py\n",
    "Function: compute_pairwise_distances at line 5\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     5                                           @profile\n",
    "     6                                           def compute_pairwise_distances(X):\n",
    "     7         1          2.0      2.0      0.0      n = X.shape[0]\n",
    "     8         1        156.0    156.0      0.0      distances = np.zeros((n, n))\n",
    "     9       101         45.0      0.4      0.0      for i in range(n):\n",
    "    10     10100       3852.0      0.4      0.2          for j in range(n):\n",
    "    11     10000      98234.0      9.8      4.0              diff = X[i] - X[j]\n",
    "    12     10000    2354031.0    235.4     95.8              distances[i, j] = np.sqrt(np.sum(diff**2))\n",
    "    13         1          0.0      0.0      0.0      return distances\n",
    "```\n",
    "\n",
    "The output shows that line 12 takes 95.8% of the total time. This tells us exactly where to focus optimization efforts: the `np.sqrt(np.sum(diff**2))` computation inside the inner loop.\n",
    "\n",
    "## Vectorization with NumPy\n",
    "\n",
    "The most common way to speed up numerical Python code is vectorization: replacing explicit loops with array operations. NumPy operations are implemented in C and operate on entire arrays at once, avoiding Python's interpreter overhead.\n",
    "\n",
    "### The Cost of Python Loops\n",
    "\n",
    "Python loops are slow because each iteration involves:\n",
    "- Looking up the loop variable\n",
    "- Type checking operands\n",
    "- Dispatching to the appropriate operation\n",
    "- Creating new Python objects for results\n",
    "\n",
    "Consider computing the element-wise sum of two arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fd34cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 ms ± 1.68 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "450 µs ± 9.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_with_loop(a, b):\n",
    "    \"\"\"Element-wise sum using a Python loop.\"\"\"\n",
    "    n = len(a)\n",
    "    result = np.empty(n)\n",
    "    for i in range(n):\n",
    "        result[i] = a[i] + b[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "def sum_vectorized(a, b):\n",
    "    \"\"\"Element-wise sum using NumPy.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# Compare performance\n",
    "n = 1000000\n",
    "a = np.random.randn(n)\n",
    "b = np.random.randn(n)\n",
    "\n",
    "%timeit sum_with_loop(a, b)\n",
    "%timeit sum_vectorized(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42985b34",
   "metadata": {},
   "source": [
    "The vectorized version is typically 50-100x faster.\n",
    "\n",
    "### Common Vectorization Patterns\n",
    "\n",
    "**Replacing conditional loops with boolean indexing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow: loop with conditional\n",
    "def clip_negative_loop(arr):\n",
    "    result = arr.copy()\n",
    "    for i in range(len(arr)):\n",
    "        if result[i] < 0:\n",
    "            result[i] = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "# Fast: boolean indexing\n",
    "def clip_negative_vectorized(arr):\n",
    "    result = arr.copy()\n",
    "    result[result < 0] = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "# Even faster: use built-in\n",
    "def clip_negative_builtin(arr):\n",
    "    return np.maximum(arr, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e92dc",
   "metadata": {},
   "source": [
    "**Computing pairwise operations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38f26c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 ms ± 803 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "699 µs ± 4.88 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Slow: nested loops\n",
    "def pairwise_diff_loop(x):\n",
    "    n = len(x)\n",
    "    result = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            result[i, j] = x[i] - x[j]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Fast: broadcasting\n",
    "def pairwise_diff_broadcast(x):\n",
    "    return x[:, np.newaxis] - x[np.newaxis, :]\n",
    "\n",
    "\n",
    "x = np.random.randn(1000)\n",
    "%timeit pairwise_diff_loop(x)\n",
    "%timeit pairwise_diff_broadcast(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36edd83",
   "metadata": {},
   "source": [
    "**Applying functions to array elements:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b9b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow: loop\n",
    "def transform_loop(arr):\n",
    "    result = np.empty_like(arr)\n",
    "    for i in range(len(arr)):\n",
    "        result[i] = np.exp(-arr[i]**2)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Fast: vectorized\n",
    "def transform_vectorized(arr):\n",
    "    return np.exp(-arr**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951b04e",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Consider the following function that computes the softmax transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a68a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loop(x):\n",
    "    \"\"\"Compute softmax using loops.\"\"\"\n",
    "    n = len(x)\n",
    "    exp_x = np.empty(n)\n",
    "    for i in range(n):\n",
    "        exp_x[i] = np.exp(x[i])\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += exp_x[i]\n",
    "    result = np.empty(n)\n",
    "    for i in range(n):\n",
    "        result[i] = exp_x[i] / total\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17bb4e",
   "metadata": {},
   "source": [
    "How would you rewrite this using NumPy vectorization? What is the single-line vectorized version?\n",
    "\n",
    "### Answer\n",
    "\n",
    "The vectorized version replaces all three loops with array operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_vectorized(x):\n",
    "    \"\"\"Compute softmax using vectorization.\"\"\"\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a8c05",
   "metadata": {},
   "source": [
    "Or as a single expression: `np.exp(x) / np.sum(np.exp(x))`. For numerical stability, subtract the maximum first: `exp_x = np.exp(x - np.max(x))`.\n",
    "\n",
    "### Memory Layout and Cache Efficiency\n",
    "\n",
    "NumPy arrays can be stored in row-major (C) or column-major (Fortran) order. Accessing elements in the storage order is faster because it uses CPU cache efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "193e17ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 µs ± 858 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "137 µs ± 1.28 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "139 µs ± 434 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "132 µs ± 2.35 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Create arrays with different memory layouts\n",
    "c_array = np.zeros((1000, 1000), order='C')  # Row-major\n",
    "f_array = np.zeros((1000, 1000), order='F')  # Column-major\n",
    "\n",
    "# Row-wise sum is faster for C-order arrays\n",
    "%timeit c_array.sum(axis=1)\n",
    "%timeit f_array.sum(axis=1)\n",
    "\n",
    "# Column-wise sum is faster for F-order arrays\n",
    "%timeit c_array.sum(axis=0)\n",
    "%timeit f_array.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d93d5",
   "metadata": {},
   "source": [
    "When performing operations that iterate over one axis, ensure the array layout matches your access pattern.\n",
    "\n",
    "### Limitations of Vectorization\n",
    "\n",
    "Vectorization works well when:\n",
    "- Operations are element-wise or have regular patterns\n",
    "- NumPy provides the needed functions\n",
    "- Memory is not a constraint (intermediate arrays fit in RAM)\n",
    "\n",
    "Vectorization is difficult when:\n",
    "- Operations depend on previous results (sequential dependencies)\n",
    "- Logic is complex with many conditionals\n",
    "- Custom algorithms don't map to NumPy operations\n",
    "\n",
    "For sequential dependencies and complex logic, we can use JIT compilation (covered later). But first, let's look at parallelization for independent tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ikc1iuxzq7i",
   "metadata": {},
   "source": [
    "## Parallelization with multiprocessing\n",
    "\n",
    "When your computation can be split into independent tasks, parallelization distributes work across multiple CPU cores. Python's `multiprocessing` module provides a way to do this without requiring special compilers or syntax.\n",
    "\n",
    "### Why multiprocessing?\n",
    "\n",
    "Python's Global Interpreter Lock (GIL) prevents multiple threads from executing Python bytecode simultaneously. This means the `threading` module doesn't provide true parallelism for CPU-bound tasks. The `multiprocessing` module sidesteps this by spawning separate Python processes, each with its own interpreter and memory space.\n",
    "\n",
    "### Using Pool for Parallel Map\n",
    "\n",
    "The most common pattern is applying a function to many inputs in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j45t8ir6qu",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_bootstrap_mean(args):\n",
    "    \"\"\"Compute mean of a bootstrap sample.\"\"\"\n",
    "    data, seed = args\n",
    "    rng = np.random.RandomState(seed)\n",
    "    sample = rng.choice(data, size=len(data), replace=True)\n",
    "    return np.mean(sample)\n",
    "\n",
    "\n",
    "# Generate some data\n",
    "data = np.random.randn(10000)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "# Serial version\n",
    "def bootstrap_serial(data, n_bootstrap):\n",
    "    results = []\n",
    "    for i in range(n_bootstrap):\n",
    "        results.append(compute_bootstrap_mean((data, i)))\n",
    "    return results\n",
    "\n",
    "# Parallel version\n",
    "def bootstrap_parallel(data, n_bootstrap, n_workers=4):\n",
    "    args = [(data, i) for i in range(n_bootstrap)]\n",
    "    with mp.Pool(n_workers) as pool:\n",
    "        results = pool.map(compute_bootstrap_mean, args)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c035b2d-4e2d-4504-896a-58168efcacd7",
   "metadata": {},
   "source": [
    "```\n",
    "%timeit bootstrap_serial(data, n_bootstrap)\n",
    "# 458 ms ± 12.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "%timeit bootstrap_parallel(data, n_bootstrap, n_workers=4)\n",
    "# 187 ms ± 8.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d96d8c-bbc7-44c6-a472-450ae2532ec0",
   "metadata": {},
   "source": [
    "With 4 workers, the parallel version is about 2-3x faster. The speedup is less than 4x due to process creation overhead and data serialization between processes.\n",
    "\n",
    "Key points about `Pool.map`:\n",
    "- Creates a pool of worker processes\n",
    "- Distributes the input list across workers\n",
    "- Each worker applies the function to its assigned inputs\n",
    "- Results are collected and returned in order\n",
    "\n",
    "The function passed to `pool.map` must be defined at the module level (not inside another function) and must be picklable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ztdp6ki9dg",
   "metadata": {},
   "source": [
    "### When to Use Parallelization\n",
    "\n",
    "Parallelization is effective when:\n",
    "- Tasks are **independent** (no shared state or dependencies between iterations)\n",
    "- Each task takes **significant time** (overhead of spawning processes is non-trivial)\n",
    "- You have **multiple CPU cores** available\n",
    "\n",
    "Parallelization is less effective when:\n",
    "- Tasks are very fast (process overhead dominates)\n",
    "- Tasks share state or need to communicate frequently\n",
    "- Memory is limited (each process has its own copy of data)\n",
    "\n",
    "### Question\n",
    "\n",
    "Consider a Monte Carlo simulation where each iteration:\n",
    "1. Generates random samples\n",
    "2. Computes a statistic\n",
    "3. Returns the result\n",
    "\n",
    "You want to run 10,000 iterations. Which parallelization approach would you use, and what potential issue should you watch out for?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Use `Pool.map` or `ProcessPoolExecutor.map` since each iteration is independent. The key issue is **random number generation**: each worker process needs its own random seed, otherwise they may generate identical random sequences. Pass a unique seed to each task (as shown in the bootstrap example above) or use `np.random.default_rng()` with different seeds per worker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9iefnqr0kyj",
   "metadata": {},
   "source": [
    "## Just-in-Time Compilation with Numba\n",
    "\n",
    "Numba is a JIT compiler that translates Python functions to optimized machine code at runtime. You can keep writing Python loops and get near-C performance.\n",
    "\n",
    "### Installing Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f05a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /Users/daiwei/.pyenv/versions/experiment/lib/python3.12/site-packages (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/daiwei/.pyenv/versions/experiment/lib/python3.12/site-packages (from numba) (0.43.0)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in /Users/daiwei/.pyenv/versions/experiment/lib/python3.12/site-packages (from numba) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd14c8e",
   "metadata": {},
   "source": [
    "### The @jit Decorator\n",
    "\n",
    "The simplest way to use Numba is the `@jit` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2255a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@jit\n",
    "def sum_array(arr):\n",
    "    \"\"\"Sum array elements using a loop.\"\"\"\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "\n",
    "\n",
    "arr = np.random.randn(1000000)\n",
    "\n",
    "# First call includes compilation time\n",
    "result = sum_array(arr)\n",
    "\n",
    "# Subsequent calls are fast\n",
    "%timeit sum_array(arr)\n",
    "%timeit np.sum(arr)  # Compare with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b60443",
   "metadata": {},
   "source": [
    "The first call to a JIT-compiled function is slow because Numba compiles the function. Subsequent calls use the compiled version and are fast.\n",
    "\n",
    "### nopython Mode\n",
    "\n",
    "By default, Numba tries to compile in \"nopython\" mode, where no Python objects are used. If it can't, it falls back to \"object\" mode, which is slower. Always use `nopython=True` (or the shorthand `@njit`) to ensure fast compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "\n",
    "@njit\n",
    "def compute_mean(arr):\n",
    "    \"\"\"Compute mean with guaranteed fast compilation.\"\"\"\n",
    "    total = 0.0\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        total += arr[i]\n",
    "    return total / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06e400",
   "metadata": {},
   "source": [
    "If Numba can't compile in nopython mode, it will raise an error instead of silently falling back to slow code.\n",
    "\n",
    "### Supported Features\n",
    "\n",
    "Numba supports a subset of Python and NumPy:\n",
    "\n",
    "**Supported:**\n",
    "- Numeric types (int, float, complex)\n",
    "- NumPy arrays and many NumPy functions\n",
    "- Loops, conditionals, basic control flow\n",
    "- Tuples (with fixed types)\n",
    "- Simple functions\n",
    "\n",
    "**Not supported:**\n",
    "- Lists with varying types\n",
    "- Dictionaries (limited support)\n",
    "- String operations\n",
    "- Classes (limited support)\n",
    "- Many Python built-ins\n",
    "\n",
    "When in doubt, check the [Numba documentation](https://numba.readthedocs.io/en/stable/reference/pysupported.html).\n",
    "\n",
    "### Example: Monte Carlo Pi Estimation\n",
    "\n",
    "Here's a practical example comparing pure Python, NumPy, and Numba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "import random\n",
    "\n",
    "\n",
    "def estimate_pi_python(n):\n",
    "    \"\"\"Estimate pi using Monte Carlo - pure Python.\"\"\"\n",
    "    inside = 0\n",
    "    for _ in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if x*x + y*y <= 1:\n",
    "            inside += 1\n",
    "    return 4 * inside / n\n",
    "\n",
    "\n",
    "def estimate_pi_numpy(n):\n",
    "    \"\"\"Estimate pi using Monte Carlo - NumPy.\"\"\"\n",
    "    x = np.random.random(n)\n",
    "    y = np.random.random(n)\n",
    "    inside = np.sum(x*x + y*y <= 1)\n",
    "    return 4 * inside / n\n",
    "\n",
    "\n",
    "@njit\n",
    "def estimate_pi_numba(n):\n",
    "    \"\"\"Estimate pi using Monte Carlo - Numba.\"\"\"\n",
    "    inside = 0\n",
    "    for _ in range(n):\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        if x*x + y*y <= 1:\n",
    "            inside += 1\n",
    "    return 4 * inside / n\n",
    "\n",
    "\n",
    "n = 10000000\n",
    "\n",
    "# Warm up Numba\n",
    "estimate_pi_numba(1000)\n",
    "\n",
    "%timeit estimate_pi_python(n)\n",
    "%timeit estimate_pi_numpy(n)\n",
    "%timeit estimate_pi_numba(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0bfcc3",
   "metadata": {},
   "source": [
    "Typical results show Numba matching or exceeding NumPy performance while keeping the simple loop structure.\n",
    "\n",
    "### Question\n",
    "\n",
    "The following Numba function fails to compile in nopython mode. Why, and how would you fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2eb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def filter_positive(arr):\n",
    "    \"\"\"Return only positive elements.\"\"\"\n",
    "    result = []\n",
    "    for x in arr:\n",
    "        if x > 0:\n",
    "            result.append(x)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc296dd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Answer\n",
    "\n",
    "The function fails because Python lists with `append()` are not fully supported in nopython mode. Numba can't know the final size of the list at compile time.\n",
    "\n",
    "Two fixes:\n",
    "\n",
    "**Fix 1: Two-pass approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def filter_positive(arr):\n",
    "    # First pass: count positives\n",
    "    count = 0\n",
    "    for x in arr:\n",
    "        if x > 0:\n",
    "            count += 1\n",
    "    # Second pass: fill result\n",
    "    result = np.empty(count)\n",
    "    j = 0\n",
    "    for x in arr:\n",
    "        if x > 0:\n",
    "            result[j] = x\n",
    "            j += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83bde04",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Fix 2: Use NumPy boolean indexing outside Numba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_positive(arr):\n",
    "    return arr[arr > 0]  # NumPy is already fast for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f1f07",
   "metadata": {},
   "source": [
    "### Parallel Loops with prange\n",
    "\n",
    "Numba can automatically parallelize loops using `prange`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def parallel_sum_squares(arr):\n",
    "    \"\"\"Sum of squares using parallel loop.\"\"\"\n",
    "    total = 0.0\n",
    "    for i in prange(len(arr)):\n",
    "        total += arr[i] ** 2\n",
    "    return total\n",
    "\n",
    "\n",
    "arr = np.random.randn(10000000)\n",
    "\n",
    "# Compare serial vs parallel\n",
    "@njit\n",
    "def serial_sum_squares(arr):\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i] ** 2\n",
    "    return total\n",
    "\n",
    "\n",
    "# Warm up\n",
    "serial_sum_squares(arr)\n",
    "parallel_sum_squares(arr)\n",
    "\n",
    "%timeit serial_sum_squares(arr)\n",
    "%timeit parallel_sum_squares(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0099acd",
   "metadata": {},
   "source": [
    "`prange` works like `range` but distributes iterations across CPU cores. Use it when iterations are independent.\n",
    "\n",
    "### When to Use Numba\n",
    "\n",
    "Numba is most effective when:\n",
    "- You have loops that can't be easily vectorized\n",
    "- Operations involve numerical computations\n",
    "- The function is called many times\n",
    "\n",
    "Numba is less effective when:\n",
    "- The function is called only once (compilation overhead dominates)\n",
    "- Operations involve strings, complex objects, or I/O\n",
    "- NumPy already provides an efficient solution\n",
    "\n",
    "## Interfacing with C/C++ Using Cython\n",
    "\n",
    "Cython is a language that combines Python syntax with C data types. It compiles to C code that can be built as a Python extension module. Cython offers:\n",
    "\n",
    "- Gradual optimization: start with Python, add types incrementally\n",
    "- Direct access to C libraries\n",
    "- Fine-grained control over memory and performance\n",
    "\n",
    "### Installing Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84fbfcf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Basic Cython Workflow\n",
    "\n",
    "Cython code is written in `.pyx` files and compiled to C extensions. Here's a minimal example:\n",
    "\n",
    "**example.pyx:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def sum_python(arr):\n",
    "    \"\"\"Pure Python - Cython compiles it.\"\"\"\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4848cda",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**setup.py:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83130fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import setup\n",
    "from Cython.Build import cythonize\n",
    "import numpy as np\n",
    "\n",
    "setup(\n",
    "    ext_modules=cythonize(\"example.pyx\"),\n",
    "    include_dirs=[np.get_include()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5c125",
   "metadata": {},
   "source": [
    "Build with: `python setup.py build_ext --inplace`\n",
    "\n",
    "Then import and use: `from example import sum_python`\n",
    "\n",
    "### Adding Type Declarations\n",
    "\n",
    "The power of Cython comes from adding C type declarations. Compare these versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ffcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "# Version 1: Pure Python (slow)\n",
    "def sum_python(arr):\n",
    "    total = 0.0\n",
    "    for i in range(len(arr)):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "\n",
    "\n",
    "# Version 2: Typed Cython (fast)\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "def sum_typed(np.ndarray[np.float64_t, ndim=1] arr):\n",
    "    cdef int i\n",
    "    cdef int n = arr.shape[0]\n",
    "    cdef double total = 0.0\n",
    "    for i in range(n):\n",
    "        total += arr[i]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc551e6",
   "metadata": {},
   "source": [
    "Key type declarations:\n",
    "- `cdef int i`: C integer for loop variable\n",
    "- `cdef double total`: C double for accumulator\n",
    "- `np.ndarray[np.float64_t, ndim=1]`: typed NumPy array\n",
    "\n",
    "These declarations eliminate Python overhead and enable C-level operations.\n",
    "\n",
    "### Disabling Bounds Checking\n",
    "\n",
    "By default, Cython checks array bounds on every access. For performance-critical code, you can disable this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def sum_fast(np.ndarray[np.float64_t, ndim=1] arr):\n",
    "    cdef int i\n",
    "    cdef int n = arr.shape[0]\n",
    "    cdef double total = 0.0\n",
    "    for i in range(n):\n",
    "        total += arr[i]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee3ad2",
   "metadata": {},
   "source": [
    "- `@boundscheck(False)`: skip array bounds checking\n",
    "- `@wraparound(False)`: skip negative index handling\n",
    "\n",
    "Only disable these when you're certain your indices are valid.\n",
    "\n",
    "### Question\n",
    "\n",
    "Consider this Cython function for computing pairwise Euclidean distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92106ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "def pairwise_distances(np.ndarray[np.float64_t, ndim=2] X):\n",
    "    cdef int n = X.shape[0]\n",
    "    cdef int d = X.shape[1]\n",
    "    cdef np.ndarray[np.float64_t, ndim=2] result = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            dist = 0.0\n",
    "            for k in range(d):\n",
    "                diff = X[i, k] - X[j, k]\n",
    "                dist += diff * diff\n",
    "            result[i, j] = dist ** 0.5\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86a160",
   "metadata": {},
   "source": [
    "What variable declarations are missing that would make this code faster?\n",
    "\n",
    "### Answer\n",
    "\n",
    "The loop variables `i`, `j`, `k` and the intermediate variables `dist` and `diff` need `cdef` declarations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def pairwise_distances(np.ndarray[np.float64_t, ndim=2] X):\n",
    "    cdef int n = X.shape[0]\n",
    "    cdef int d = X.shape[1]\n",
    "    cdef int i, j, k\n",
    "    cdef double dist, diff\n",
    "    cdef np.ndarray[np.float64_t, ndim=2] result = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            dist = 0.0\n",
    "            for k in range(d):\n",
    "                diff = X[i, k] - X[j, k]\n",
    "                dist += diff * diff\n",
    "            result[i, j] = dist ** 0.5\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810adf7c",
   "metadata": {},
   "source": [
    "Without `cdef`, each variable is a Python object, requiring type checking and memory allocation on every operation.\n",
    "\n",
    "### Using Typed Memoryviews\n",
    "\n",
    "Modern Cython recommends typed memoryviews instead of NumPy array syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef095a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport cython\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def sum_memoryview(double[:] arr):\n",
    "    cdef int i\n",
    "    cdef int n = arr.shape[0]\n",
    "    cdef double total = 0.0\n",
    "    for i in range(n):\n",
    "        total += arr[i]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04609a85",
   "metadata": {},
   "source": [
    "Memoryviews (`double[:]` for 1D, `double[:, :]` for 2D) work with any object that supports the buffer protocol, not just NumPy arrays.\n",
    "\n",
    "### Calling C Libraries\n",
    "\n",
    "Cython can directly call C functions. For example, using the C math library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.math cimport sqrt, exp, log\n",
    "\n",
    "cdef double fast_gaussian(double x, double mu, double sigma):\n",
    "    cdef double z = (x - mu) / sigma\n",
    "    return exp(-0.5 * z * z) / (sigma * sqrt(2 * 3.14159265358979))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce778a5",
   "metadata": {},
   "source": [
    "This avoids the overhead of Python's `math` module.\n",
    "\n",
    "### Pure Python Mode\n",
    "\n",
    "Cython 3.0+ supports pure Python syntax using type annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_pure.py\n",
    "import cython\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@cython.cfunc\n",
    "def compute_sum(arr: cython.double[:]) -> cython.double:\n",
    "    i: cython.int\n",
    "    n: cython.int = arr.shape[0]\n",
    "    total: cython.double = 0.0\n",
    "    for i in range(n):\n",
    "        total += arr[i]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e637e",
   "metadata": {},
   "source": [
    "This can be run as regular Python or compiled with Cython for speed.\n",
    "\n",
    "### Cython vs Numba\n",
    "\n",
    "| Feature | Numba | Cython |\n",
    "|---------|-------|--------|\n",
    "| Ease of use | Simple decorator | Requires compilation step |\n",
    "| Compilation | JIT (at runtime) | AOT (ahead of time) |\n",
    "| C library access | Limited | Full access |\n",
    "| Debugging | Harder | Easier (generates readable C) |\n",
    "| Distribution | Include Numba dependency | Distribute compiled extensions |\n",
    "| Learning curve | Lower | Higher |\n",
    "\n",
    "**Use Numba when:**\n",
    "- You want quick speedups with minimal code changes\n",
    "- Your algorithm uses standard numerical operations\n",
    "- You don't need to call external C libraries\n",
    "\n",
    "**Use Cython when:**\n",
    "- You need to wrap existing C/C++ code\n",
    "- You want fine-grained control over optimization\n",
    "- You're distributing a package and want to avoid runtime dependencies\n",
    "\n",
    "## Putting It All Together\n",
    "\n",
    "Here's a workflow for optimizing Python code:\n",
    "\n",
    "1. **Write correct code first.** Don't optimize prematurely. Make sure your code produces correct results.\n",
    "\n",
    "2. **Profile to find bottlenecks.** Use `cProfile` to identify which functions take the most time.\n",
    "\n",
    "3. **Try vectorization.** Can the slow code be rewritten using NumPy operations? This is often the simplest solution.\n",
    "\n",
    "4. **Consider Numba.** If vectorization doesn't work, try adding `@njit`. This works well for numerical loops.\n",
    "\n",
    "5. **Use Cython for special cases.** When you need to call C libraries or want maximum control, Cython is the tool.\n",
    "\n",
    "6. **Verify correctness.** After optimization, ensure the code still produces correct results. Compare outputs against the original implementation.\n",
    "\n",
    "### Example: Optimizing a Statistical Function\n",
    "\n",
    "Let's optimize a function that computes the log-likelihood of a Gaussian mixture model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def gmm_log_likelihood_python(X, weights, means, covs):\n",
    "    \"\"\"Compute GMM log-likelihood - pure Python.\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    n_components = len(weights)\n",
    "\n",
    "    log_likelihood = 0.0\n",
    "    for i in range(n_samples):\n",
    "        sample_prob = 0.0\n",
    "        for k in range(n_components):\n",
    "            diff = X[i] - means[k]\n",
    "            cov_inv = np.linalg.inv(covs[k])\n",
    "            det = np.linalg.det(covs[k])\n",
    "            exponent = -0.5 * diff @ cov_inv @ diff\n",
    "            prob = weights[k] * np.exp(exponent) / np.sqrt((2*np.pi)**len(diff) * det)\n",
    "            sample_prob += prob\n",
    "        log_likelihood += np.log(sample_prob)\n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470523d",
   "metadata": {},
   "source": [
    "**Step 1: Profile**\n",
    "\n",
    "The nested loops and repeated matrix inversions are clear bottlenecks.\n",
    "\n",
    "**Step 2: Vectorize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_log_likelihood_vectorized(X, weights, means, covs):\n",
    "    \"\"\"Compute GMM log-likelihood - vectorized.\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_components = len(weights)\n",
    "\n",
    "    # Precompute inverse and determinant for each component\n",
    "    precisions = [np.linalg.inv(cov) for cov in covs]\n",
    "    log_dets = [np.log(np.linalg.det(cov)) for cov in covs]\n",
    "\n",
    "    # Compute log probabilities for all samples and components\n",
    "    log_probs = np.zeros((n_samples, n_components))\n",
    "    for k in range(n_components):\n",
    "        diff = X - means[k]  # (n_samples, n_features)\n",
    "        mahal = np.sum(diff @ precisions[k] * diff, axis=1)\n",
    "        log_probs[:, k] = (np.log(weights[k])\n",
    "                          - 0.5 * n_features * np.log(2*np.pi)\n",
    "                          - 0.5 * log_dets[k]\n",
    "                          - 0.5 * mahal)\n",
    "\n",
    "    # Log-sum-exp for numerical stability\n",
    "    max_log_probs = np.max(log_probs, axis=1)\n",
    "    log_likelihood = np.sum(max_log_probs +\n",
    "                           np.log(np.sum(np.exp(log_probs - max_log_probs[:, np.newaxis]), axis=1)))\n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40c2dc",
   "metadata": {},
   "source": [
    "This version moves the sample loop into NumPy operations, keeping only the component loop in Python.\n",
    "\n",
    "### Question\n",
    "\n",
    "Looking at the vectorized GMM function above, what additional optimization could Numba provide, and what limitations might you encounter?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Numba could potentially speed up the remaining component loop, but there are limitations:\n",
    "\n",
    "1. **`np.linalg.inv` and `np.linalg.det`** are supported in Numba, but performance gains may be modest since they're already calling optimized LAPACK routines.\n",
    "\n",
    "2. **The main benefit** would come from JIT-compiling the Mahalanobis distance computation if we unrolled it into explicit loops.\n",
    "\n",
    "3. **Limitation:** For this problem, the vectorized NumPy version is likely already near-optimal because the heavy lifting (matrix operations) is done by optimized BLAS/LAPACK libraries. Numba shines more when you have complex control flow that can't be vectorized.\n",
    "\n",
    "The best approach here is probably the vectorized version, possibly using `scipy.stats.multivariate_normal.logpdf` which is already optimized.\n",
    "\n",
    "## Summary\n",
    "\n",
    "* **Profile first:** Use `timeit` and `cProfile` to identify bottlenecks before optimizing.\n",
    "\n",
    "* **Vectorize with NumPy:** Replace Python loops with array operations. This is often the simplest and most effective optimization.\n",
    "\n",
    "* **Use Numba for numerical loops:** Add `@njit` to functions with loops that can't be vectorized. Numba compiles Python to machine code with minimal code changes.\n",
    "\n",
    "* **Use Cython for C integration:** When you need to wrap C libraries or want maximum control, Cython compiles Python-like code to C extensions.\n",
    "\n",
    "* **Parallelize independent tasks:** Use `multiprocessing.Pool` or `ProcessPoolExecutor` to distribute work across CPU cores when tasks are independent.\n",
    "\n",
    "* **Verify correctness:** Always test that optimized code produces the same results as the original.\n",
    "\n",
    "## Recommended Resources\n",
    "\n",
    "* [Python Profiling Guide](https://realpython.com/python-profiling/)\n",
    "* [NumPy Performance Tips](https://numpy.org/doc/stable/user/basics.indexing.html)\n",
    "* [Numba Documentation](https://numba.readthedocs.io/en/stable/)\n",
    "* [Cython Documentation](https://cython.readthedocs.io/en/latest/)\n",
    "* [High Performance Python (Book)](https://www.oreilly.com/library/view/high-performance-python/9781492055013/)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
